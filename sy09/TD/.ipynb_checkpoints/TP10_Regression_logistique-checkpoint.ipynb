{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from TP07_K_plus_proches_voisins.src.utils import add_decision_boundary\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams[\"figure.figsize\"] = (4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Q1\n",
    "Xy = pd.read_csv(\"TP09_Analyse_discriminante_de_donnees_gaussiennes/data/SynthPara_n1000_p2.csv\")\n",
    "X = Xy.iloc[:, :-1]\n",
    "y = Xy.iloc[:, -1]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "cls = LogisticRegression(penalty=\"none\")\n",
    "cls.fit(X, y)\n",
    "sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"z\", data=Xy)\n",
    "add_decision_boundary(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "print(cls.coef_)\n",
    "print(cls.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"z\", data=Xy)\n",
    "levels = [.1, .5, .9]\n",
    "add_decision_boundary(cls, levels=levels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Régression logistique quadratique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1], [2], [3]])\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "Xy = pd.read_csv(\"TP07_K_plus_proches_voisins/data/Synth1-2000.csv\")\n",
    "X = Xy.iloc[:, :-1]\n",
    "y = Xy.iloc[:, -1]\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "Y = poly.fit_transform(X)\n",
    "cls = LogisticRegression()\n",
    "cls.fit(Y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5\n",
    "from sklearn.pipeline import make_pipeline\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "cls = LogisticRegression()\n",
    "pipe = make_pipeline(poly, cls)\n",
    "pipe.fit(X, y)\n",
    "sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"y\", data=Xy)\n",
    "add_decision_boundary(pipe, label=\"LogRegQuad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation de la régression logistique binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10\n",
    "from sklearn.linear_model import LogisticRegression as SklearnLogisticRegression\n",
    "Xy = pd.read_csv(\"TP09_Analyse_discriminante_de_donnees_gaussiennes/data/SynthPara_n1000_p2.csv\")\n",
    "X = Xy.iloc[:, :-1]\n",
    "y = Xy.iloc[:, -1]\n",
    "sk_cls = SklearnLogisticRegression(penalty=\"none\")\n",
    "sk_cls.fit(X, y)\n",
    "print(sk_cls.coef_)\n",
    "print(sk_cls.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TP10_Regression_logistique.src.logistic_regression import LogisticRegression\n",
    "cls = LogisticRegression()\n",
    "cls.fit(X, y)\n",
    "print(cls.coef_)\n",
    "print(cls.intercept_)\n",
    "print(np.isclose(sk_cls.coef_, cls.coef_))\n",
    "print(np.isclose(sk_cls.intercept_, cls.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"z\", data=Xy)\n",
    "add_decision_boundary(cls, label=\"LogReg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique sur données transformées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8\n",
    "from sklearn.cluster import KMeans\n",
    "Xy = pd.read_csv(\"TP07_K_plus_proches_voisins/data/Synth1-2000.csv\")\n",
    "X = Xy.iloc[:, :-1]\n",
    "y = Xy.iloc[:, -1]\n",
    "cls = KMeans(n_clusters=20)\n",
    "cls.fit(X)\n",
    "centers = cls.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9\n",
    "from sklearn.metrics import pairwise_distances\n",
    "Y = pairwise_distances(X, centers)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def distances_to_centers(centers, metric=\"euclidean\"):\n",
    "    def distances_to_centers0(X):\n",
    "    # Calcul des inter-distances entre `X` et `centers`\n",
    "        return pairwise_distances(X, centers, metric=metric)\n",
    "    return distances_to_centers0\n",
    "\n",
    "# Fonction qui prend en argument un jeu de données et le transforme.\n",
    "func = distances_to_centers(centers)\n",
    "\n",
    "# Création d'un modèle Scikit-learn qui réalise la transformation voulue.\n",
    "transformer = FunctionTransformer(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q11\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(transformer, LogisticRegression())\n",
    "pipe.fit(X, y)\n",
    "ax = sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"y\", data=Xy)\n",
    "plt.scatter(*centers.T, marker=\"s\", c=\"r\")\n",
    "add_decision_boundary(pipe)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12\n",
    "func = distances_to_centers(centers, metric=\"sqeuclidean\")\n",
    "transformer = FunctionTransformer(func)\n",
    "pipe = make_pipeline(transformer, LogisticRegression())\n",
    "pipe.fit(X, y)\n",
    "sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"y\", data=Xy)\n",
    "add_decision_boundary(pipe)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q13\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import pairwise_distances\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_clusters, metric=\"euclidean\"):\n",
    "        # Le nombre de centres à apprendre sur le jeu de données de\n",
    "        # départ\n",
    "        self.n_clusters = n_clusters\n",
    "\n",
    "        # La métrique utilisée pour calculer les distances entre les\n",
    "        # centres et les exemples du jeu de données\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Apprentissage des centres et stockage dans l'attribut\n",
    "        # `centers`.\n",
    "        km = KMeans(n_clusters=self.n_clusters)\n",
    "        km.fit(X)\n",
    "        self.centers = km.cluster_centers_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Retourner les données transformées en utilisant les centres\n",
    "        # disponibles avec l'attribut `centers`\n",
    "        return pairwise_distances(X, self.centers, metric=self.metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q14\n",
    "pipe = make_pipeline(CustomTransformer(10), LogisticRegression())\n",
    "pipe.fit(X, y)\n",
    "sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"y\", data=Xy)\n",
    "add_decision_boundary(pipe, label=\"K=10\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q15\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([(\"tf\", CustomTransformer(10)), (\"logreg\", LogisticRegression())])\n",
    "n_clusters_list = np.unique(np.round(np.geomspace(1, 500, 20)).astype(int))\n",
    "param_grid = {\"tf__n_clusters\": n_clusters_list}\n",
    "search = GridSearchCV(pipe, param_grid, scoring=\"accuracy\", cv=5)\n",
    "search.fit(X, y)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    (\n",
    "        dict(n_clusters=d[\"tf__n_clusters\"], accuracy=e, std=s)\n",
    "        for d, e, s in zip(\n",
    "            search.cv_results_[\"params\"],\n",
    "            search.cv_results_[\"mean_test_score\"],\n",
    "            search.cv_results_[\"std_test_score\"],\n",
    "    )\n",
    "    )\n",
    ")\n",
    "plt.errorbar(df[\"n_clusters\"], df[\"accuracy\"], yerr=df[\"std\"])\n",
    "plt.xscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kopt = df.loc[df.accuracy.idxmax(), \"n_clusters\"]\n",
    "acc_opt = df.loc[df.accuracy.idxmax(), \"accuracy\"]\n",
    "std_opt = df.loc[df.accuracy.idxmax(), \"std\"]\n",
    "Kopt = min(df.loc[df.accuracy >= acc_opt - std_opt, \"n_clusters\"])\n",
    "Kopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(CustomTransformer(Kopt), LogisticRegression())\n",
    "pipe.fit(X, y)\n",
    "sns.scatterplot(x=\"X1\", y=\"X2\", hue=\"y\", data=Xy)\n",
    "centers = pipe[0].centers\n",
    "plt.scatter(*centers.T, marker=\"s\", c=\"r\")\n",
    "add_decision_boundary(pipe, label=f\"K={Kopt}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des coefficients de la régression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = pd.read_csv(\"TP10_Regression_logistique/data/SAheart.csv\")\n",
    "X = Xy.iloc[:, 1:-1]\n",
    "y = Xy.iloc[:, -1]\n",
    "X = X.replace({\"famhist\": {\"Present\": 1, \"Absent\": 0}})\n",
    "X = X.drop([\"adiposity\", \"typea\"], axis=1)\n",
    "X[\"intercept\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q16\n",
    "cls = SklearnLogisticRegression(fit_intercept=False, penalty=\"none\", solver=\"newton-cg\")\n",
    "cls.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q17\n",
    "import scipy.stats as spst\n",
    "def Waldtest_LR(model, X):\n",
    "    prob = model.predict_proba(X)\n",
    "    What = np.diag(np.product(prob, axis=1))\n",
    "    In_F = X.T @ What @ X\n",
    "    shat = np.sqrt(np.diag(np.linalg.inv(In_F)))\n",
    "    zscores = model.coef_ / shat\n",
    "    nonsign = np.abs(zscores) <= spst.norm.ppf(1 - 0.05 / 2, loc=0, scale=1)\n",
    "    return zscores, nonsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.columns[Waldtest_LR(cls, X)[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Waldtest_LR(cls, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q18\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def loglike_LR(model, X, y):\n",
    "    targ = np.column_stack((1 - y, y))\n",
    "    prob = model.predict_proba(X)\n",
    "    return -log_loss(targ, prob, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy as cp\n",
    "\n",
    "ll = loglike_LR(cls, X, y)\n",
    "X_ = cp.copy(X)\n",
    "cls_ = SklearnLogisticRegression(fit_intercept=False, penalty=\"none\", solver=\"newton-cg\")\n",
    "cls_.fit(X_, y)\n",
    "ll_ = loglike_LR(cls_, X_, y)\n",
    "\n",
    "while 2 * (ll - ll_) <= spst.chi2.ppf(1 - 0.05, 1):\n",
    "    Xopt = cp.copy(X_)\n",
    "    clsopt = cp.copy(cls_)\n",
    "    llopt = cp.copy(ll_)\n",
    "    X_.drop(columns=X_.columns[np.abs(Waldtest_LR(cls_, X_)[0]).argmin()], inplace=True)\n",
    "    cls_.fit(X_, y)\n",
    "    ll_ = loglike_LR(cls_, X_, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy as cp\n",
    "\n",
    "ll = loglike_LR(cls, X, y)\n",
    "X_ = cp.copy(X)\n",
    "cls_ = SklearnLogisticRegression(fit_intercept=False, penalty=\"none\", solver=\"newton-cg\")\n",
    "cls_.fit(X_, y)\n",
    "ll_ = loglike_LR(cls_, X_, y)\n",
    "\n",
    "while 2 * (ll - ll_) <= spst.chi2.ppf(1 - 0.05, 1):\n",
    "    Xopt = cp.copy(X_)\n",
    "    clsopt = cp.copy(cls_)\n",
    "    llopt = cp.copy(ll_)\n",
    "    lltab = np.zeros(Xopt.shape[1])\n",
    "    for i in range(Xopt.shape[1]):\n",
    "        X_ = cp.copy(Xopt)\n",
    "        X_.drop(columns=X_.columns[i], inplace=True)\n",
    "        cls_.fit(X_, y)\n",
    "        lltab[i] = loglike_LR(cls_, X_, y)\n",
    "        \n",
    "    X_ = cp.copy(Xopt)\n",
    "    X_.drop(columns=X_.columns[lltab.argmax()], inplace=True)\n",
    "    cls_.fit(X_, y)\n",
    "    ll_ = loglike_LR(cls_, X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xopt.columns)\n",
    "print(clsopt.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
